{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import configparser\n",
    "import json\n",
    "\n",
    "from boto3_utils import (\n",
    "    get_bucket,\n",
    "    get_subbucket,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "with open('dwh.cfg') as inp:\n",
    "    config.read_file(inp)\n",
    "\n",
    "KEY                    = config.get('AWS','KEY')\n",
    "SECRET                 = config.get('AWS','SECRET')\n",
    "\n",
    "HOST                   = config.get('CLUSTER', 'HOST')\n",
    "CLUSTER_NAME           = config.get('CLUSTER', 'CLUSTER_NAME')\n",
    "DWH_CLUSTER_TYPE       = config.get('CLUSTER', 'DWH_CLUSTER_TYPE')\n",
    "DWH_NUM_NODES          = config.get('CLUSTER', 'DWH_NUM_NODES')\n",
    "DWH_NODE_TYPE          = config.get('CLUSTER', 'DWH_NODE_TYPE')\n",
    "\n",
    "DB_NAME                = config.get('CLUSTER', 'DB_NAME')\n",
    "DB_USER                = config.get('CLUSTER', 'DB_USER')\n",
    "DB_PASSWORD            = config.get('CLUSTER', 'DB_PASSWORD')\n",
    "DB_PORT                = config.get('CLUSTER', 'DB_PORT')\n",
    "\n",
    "ARN                    = config.get('IAM_ROLE', 'ARN')\n",
    "IAM_ROLE_NAME          = config.get('IAM_ROLE', 'IAM_ROLE_NAME')\n",
    "\n",
    "S3_LOG_DATA            = config.get('S3', 'LOG_DATA')\n",
    "S3_LOG_JSONPATH        = config.get('S3', 'LOG_JSONPATH')\n",
    "S3_SONG_DATA           = config.get('S3', 'SONG_DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "common_kwargs = {\n",
    "    'region_name': 'us-west-2',\n",
    "    'aws_access_key_id': KEY,\n",
    "    'aws_secret_access_key': SECRET,\n",
    "}\n",
    "\n",
    "ec2 = boto3.resource(\n",
    "    'ec2',\n",
    "    **common_kwargs,\n",
    ")\n",
    "\n",
    "s3_resource = boto3.resource(\n",
    "    's3',\n",
    "    **common_kwargs,\n",
    ")\n",
    "\n",
    "iam = boto3.client(\n",
    "    'iam',\n",
    "    **common_kwargs,\n",
    ")\n",
    "\n",
    "redshift = boto3.client(\n",
    "    'redshift',\n",
    "    **common_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Let's first check out the log data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "bucket = s3_resource.Bucket(get_bucket(S3_LOG_DATA))\n",
    "for obj in bucket.objects.filter(Prefix=get_subbucket(S3_LOG_DATA)):\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "json_filename = obj.key.split('/')[-1]\n",
    "s3_resource.meta.client.download_file(\n",
    "    obj.bucket_name,\n",
    "    obj.key,\n",
    "    json_filename,\n",
    ")\n",
    "\n",
    "with open(json_filename) as inp:\n",
    "    for line in inp.readlines():\n",
    "        log_json = json.loads(line)\n",
    "        break\n",
    "    \n",
    "log_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Now, let's check out the song data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "bucket = s3_resource.Bucket(get_bucket(S3_SONG_DATA))\n",
    "for i, obj in enumerate(bucket.objects.filter(Prefix=get_subbucket(S3_SONG_DATA))):\n",
    "    print(obj)\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "json_filename = obj.key.split('/')[-1]\n",
    "s3_resource.meta.client.download_file(\n",
    "    obj.bucket_name,\n",
    "    obj.key,\n",
    "    json_filename,\n",
    ")\n",
    "\n",
    "with open(json_filename) as inp:\n",
    "    for line in inp.readlines():\n",
    "        log_json = json.loads(line)\n",
    "        break\n",
    "    \n",
    "log_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Finally, let's see what's in the log data json path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "bucket = s3_resource.Bucket(get_bucket(S3_LOG_JSONPATH))\n",
    "for obj in bucket.objects.filter(Prefix=get_subbucket(S3_LOG_JSONPATH)):\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "S3_LOG_JSONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "json_filename = S3_LOG_JSONPATH.split('/')[-1]\n",
    "s3_resource.meta.client.download_file(\n",
    "    get_bucket(S3_LOG_JSONPATH),\n",
    "    get_subbucket(S3_LOG_JSONPATH),\n",
    "    json_filename,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(json_filename) as inp:\n",
    "    log_json = json.load(inp)\n",
    "    \n",
    "log_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Creating an IAM Role that makes Redshift able to access S3 bucket (ReadOnly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "if ARN:\n",
    "    roleArn = ARN\n",
    "else:    \n",
    "    iam.get_role(\n",
    "        RoleName=IAM_ROLE_NAME\n",
    "    )['Role']['Arn']\n",
    "\n",
    "    iam.create_role(\n",
    "        Path='/',\n",
    "        RoleName=IAM_ROLE_NAME,\n",
    "        Description = 'Allows Redshift clusters to call AWS services on your behalf.',\n",
    "        AssumeRolePolicyDocument=json.dumps({\n",
    "            'Statement': [{\n",
    "                'Action': 'sts:AssumeRole',\n",
    "                'Effect': 'Allow',\n",
    "                'Principal': {\n",
    "                    'Service': 'redshift.amazonaws.com'\n",
    "                }\n",
    "            }],\n",
    "            'Version': '2012-10-17'\n",
    "        })\n",
    "    )\n",
    "\n",
    "    iam.attach_role_policy(\n",
    "        RoleName=IAM_ROLE_NAME,\n",
    "        PolicyArn='arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess'\n",
    "    )['ResponseMetadata']['HTTPStatusCode']\n",
    "    \n",
    "    roleArn = iam.get_role(RoleName=IAM_ROLE_NAME)['Role']['Arn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Creating a Redshift cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    response = redshift.create_cluster(        \n",
    "        #HW\n",
    "        ClusterType=DWH_CLUSTER_TYPE,\n",
    "        NodeType=DWH_NODE_TYPE,\n",
    "        NumberOfNodes=int(DWH_NUM_NODES),\n",
    "\n",
    "        #Identifiers & Credentials\n",
    "        DBName=DB_NAME,\n",
    "        ClusterIdentifier=CLUSTER_NAME,\n",
    "        MasterUsername=DB_USER,\n",
    "        MasterUserPassword=DB_PASSWORD,\n",
    "\n",
    "        #Roles (for s3 access)\n",
    "        IamRoles=[ARN]  \n",
    "    )\n",
    "except ClientError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "myClusterProps = redshift.describe_clusters(\n",
    "    ClusterIdentifier=CLUSTER_NAME\n",
    ")['Clusters'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Opening an incoming TCP port to access the cluster endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "vpc = ec2.Vpc(id=myClusterProps['VpcId'])\n",
    "defaultSg = list(vpc.security_groups.all())[0]\n",
    "# print(defaultSg)\n",
    "try:\n",
    "    defaultSg.authorize_ingress(\n",
    "        GroupName=defaultSg.group_name,\n",
    "        CidrIp='0.0.0.0/0',\n",
    "        IpProtocol='TCP',\n",
    "        FromPort=int(DB_PORT),\n",
    "        ToPort=int(DB_PORT)\n",
    "    )\n",
    "except ClientError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Connect to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "if not HOST:\n",
    "    HOST = myClusterProps['Endpoint']['Address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "conn_string = f'postgresql://{DB_USER}:{DB_PASSWORD}@{HOST}:{DB_PORT}/{DB_NAME}'\n",
    "# print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE SCHEMA IF NOT EXISTS sparkify;\n",
    "SET search_path TO sparkify;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "This is an example event JSON:\n",
    "```json\n",
    "{'artist': 'Stephen Lynch',\n",
    " 'auth': 'Logged In',\n",
    " 'firstName': 'Jayden',\n",
    " 'gender': 'M',\n",
    " 'itemInSession': 0,\n",
    " 'lastName': 'Bell',\n",
    " 'length': 182.85669,\n",
    " 'level': 'free',\n",
    " 'location': 'Dallas-Fort Worth-Arlington, TX',\n",
    " 'method': 'PUT',\n",
    " 'page': 'NextSong',\n",
    " 'registration': 1540991795796.0,\n",
    " 'sessionId': 829,\n",
    " 'song': \"Jim Henson's Dead\",\n",
    " 'status': 200,\n",
    " 'ts': 1543537327796,\n",
    " 'userAgent': 'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; WOW64; Trident/6.0)',\n",
    " 'userId': '91'}\n",
    "```\n",
    "and let's remember:\n",
    "```json\n",
    "{'jsonpaths': [\"$['artist']\",\n",
    "  \"$['auth']\",\n",
    "  \"$['firstName']\",\n",
    "  \"$['gender']\",\n",
    "  \"$['itemInSession']\",\n",
    "  \"$['lastName']\",\n",
    "  \"$['length']\",\n",
    "  \"$['level']\",\n",
    "  \"$['location']\",\n",
    "  \"$['method']\",\n",
    "  \"$['page']\",\n",
    "  \"$['registration']\",\n",
    "  \"$['sessionId']\",\n",
    "  \"$['song']\",\n",
    "  \"$['status']\",\n",
    "  \"$['ts']\",\n",
    "  \"$['userAgent']\",\n",
    "  \"$['userId']\"]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS event_staging;\n",
    "\n",
    "CREATE TABLE event_staging (\n",
    "    artist          TEXT,\n",
    "    auth            TEXT        NOT NULL,\n",
    "    firstName       TEXT,\n",
    "    gender          CHAR(1),\n",
    "    itemInSession   INTEGER     NOT NULL,\n",
    "    lastName        TEXT,\n",
    "    length          NUMERIC,\n",
    "    level           TEXT        NOT NULL,\n",
    "    location        TEXT,\n",
    "    method          TEXT        NOT NULL,\n",
    "    page            TEXT        NOT NULL,\n",
    "    registration    NUMERIC,\n",
    "    sessionId       INTEGER     NOT NULL,\n",
    "    song            VARCHAR,\n",
    "    status          INTEGER     NOT NULL,\n",
    "    ts              NUMERIC     NOT NULL,\n",
    "    userAgent       VARCHAR,\n",
    "    userId          INTEGER\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY event_staging FROM 's3://udacity-dend/log_data'\n",
    "IAM_ROLE 'arn:aws:iam::474811394246:role/dwhRole'\n",
    "FORMAT AS JSON 's3://udacity-dend/log_json_path.json';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "After several trials-and-errors, the above worked.\n",
    "\n",
    "What really helped was taking a peek into the following table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT starttime, err_code, err_reason\n",
    "FROM stl_load_errors\n",
    "ORDER BY starttime DESC\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let's turn the `COPY` statement into a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "query = get_copy_json_query('event_staging', S3_LOG_DATA, ARN, S3_LOG_JSONPATH)\n",
    "\n",
    "%sql $query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "OK, now let's remind ourselves how a song JSON looks like:\n",
    "```json\n",
    "{'artist_id': 'ARGE7G11187FB37E05',\n",
    " 'artist_latitude': None,\n",
    " 'artist_location': 'Brooklyn, NY',\n",
    " 'artist_longitude': None,\n",
    " 'artist_name': 'Cyndi Lauper',\n",
    " 'duration': 240.63955,\n",
    " 'num_songs': 1,\n",
    " 'song_id': 'SONRWUU12AF72A4283',\n",
    " 'title': 'Into The Nightlife',\n",
    " 'year': 2008}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS song_staging;\n",
    "\n",
    "CREATE TABLE song_staging (\n",
    "    artist_id        TEXT      NOT NULL,\n",
    "    artist_latitude  TEXT,\n",
    "    artist_longitude TEXT,\n",
    "    artist_location  TEXT,\n",
    "    artist_name      TEXT      NOT NULL,\n",
    "    duration         NUMERIC   NOT NULL,\n",
    "    num_songs        INTEGER   NOT NULL,\n",
    "    song_id          TEXT      NOT NULL,\n",
    "    title            TEXT      NOT NULL,\n",
    "    year             INTEGER   NOT NULL\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "query = get_copy_json_query('song_staging', S3_SONG_DATA, ARN)\n",
    "\n",
    "%sql $query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS songplays CASCADE;\n",
    "\n",
    "CREATE TABLE songplays (\n",
    "  songplay_id    INTEGER         IDENTITY(0, 1)     PRIMARY KEY,\n",
    "  start_time     TIMESTAMP       NOT NULL,\n",
    "  user_id        INTEGER         NOT NULL,\n",
    "  level          TEXT            NOT NULL,\n",
    "  song_id        TEXT,\n",
    "  artist_id      TEXT,\n",
    "  session_id     INTEGER         NOT NULL,\n",
    "  location       TEXT,\n",
    "  user_agent     TEXT            NOT NULL\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "INSERT INTO songplays (\n",
    "    start_time, user_id, level, song_id, artist_id,\n",
    "    session_id, location, user_agent\n",
    ")\n",
    "SELECT\n",
    "    timestamp 'epoch' + es.ts / 1000 * interval '1 second' AS start_time,\n",
    "    es.userId                                              AS user_id,\n",
    "    es.level,\n",
    "    ss.song_id,\n",
    "    ss.artist_id,\n",
    "    es.sessionId as session_id,\n",
    "    es.location,\n",
    "    es.userAgent as user_agent\n",
    "FROM\n",
    "    event_staging AS es\n",
    "JOIN\n",
    "    song_staging AS ss ON (\n",
    "        es.song = ss.title AND es.artist = ss.artist_name\n",
    "    )\n",
    "WHERE\n",
    "    es.page = 'NextSong';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%sql SELECT * FROM songplays LIMIT 2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### It works!\n",
    "Now, let's populate the rest of the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS users;\n",
    "\n",
    "CREATE TABLE users (\n",
    "  user_id        INTEGER                            PRIMARY KEY,\n",
    "  first_name     TEXT            NOT NULL,\n",
    "  last_name      TEXT            NOT NULL,\n",
    "  gender         CHAR(1)         NOT NULL,\n",
    "  level          TEXT            NOT NULL\n",
    ");\n",
    "\n",
    "INSERT INTO users (\n",
    "    user_id, first_name, last_name,\n",
    "    gender, level\n",
    ")\n",
    "SELECT\n",
    "    es.userId,\n",
    "    es.firstName,\n",
    "    es.lastName,\n",
    "    es.gender,\n",
    "    es.level\n",
    "FROM\n",
    "    event_staging AS es\n",
    "JOIN (\n",
    "    SELECT\n",
    "        max(ts) AS ts,\n",
    "        userId\n",
    "    FROM\n",
    "        event_staging\n",
    "    WHERE\n",
    "        page = 'NextSong'\n",
    "    GROUP BY\n",
    "        userId\n",
    "    ) AS max_ts_for_user\n",
    "ON (\n",
    "    es.userId = max_ts_for_user.userId AND es.ts = max_ts_for_user.ts\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%sql SELECT * FROM users LIMIT 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS songs;\n",
    "\n",
    "CREATE TABLE songs (\n",
    "  song_id        TEXT                               PRIMARY KEY,\n",
    "  title          TEXT            NOT NULL,\n",
    "  artist_id      TEXT            NOT NULL,\n",
    "  year           INTEGER         NOT NULL,\n",
    "  duration       NUMERIC         NOT NULL\n",
    ");\n",
    "\n",
    "INSERT INTO songs\n",
    "SELECT\n",
    "    song_id,\n",
    "    title,\n",
    "    artist_id,\n",
    "    year,\n",
    "    duration\n",
    "FROM\n",
    "    song_staging;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%sql SELECT * from songs LIMIT 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS time;\n",
    "\n",
    "CREATE TABLE time (\n",
    "  start_time    TIMESTAMP                           PRIMARY KEY,\n",
    "  hour          INTEGER          NOT NULL,\n",
    "  day           INTEGER          NOT NULL,\n",
    "  week          INTEGER          NOT NULL,\n",
    "  month         INTEGER          NOT NULL,\n",
    "  year          INTEGER          NOT NULL,\n",
    "  weekday       INTEGER          NOT NULL\n",
    ");\n",
    "\n",
    "INSERT INTO time (\n",
    "    start_time, hour, day, week,\n",
    "    month, year, weekday\n",
    ")\n",
    "SELECT\n",
    "    timestamp_eval.start_time                       AS start_time,\n",
    "    EXTRACT(hour FROM timestamp_eval.start_time)    AS hour,\n",
    "    EXTRACT(day FROM timestamp_eval.start_time)     AS day,\n",
    "    EXTRACT(week FROM timestamp_eval.start_time)    AS week,\n",
    "    EXTRACT(month FROM timestamp_eval.start_time)   AS month,\n",
    "    EXTRACT(year FROM timestamp_eval.start_time)    AS year,\n",
    "    EXTRACT(weekday FROM timestamp_eval.start_time) AS weekday\n",
    "FROM (\n",
    "    SELECT DISTINCT\n",
    "        TIMESTAMP 'epoch' + event_staging.ts/1000 * INTERVAL '1 second' AS start_time\n",
    "    FROM \n",
    "        event_staging\n",
    "    WHERE\n",
    "        page = 'NextSong'\n",
    ") timestamp_eval;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%sql SELECT * FROM time LIMIT 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS artists;\n",
    "\n",
    "CREATE TABLE artists (\n",
    "  artist_id     TEXT                                PRIMARY KEY,\n",
    "  name          TEXT             NOT NULL,\n",
    "  location      TEXT,\n",
    "  latitude      NUMERIC,\n",
    "  longitude     NUMERIC\n",
    ");\n",
    "\n",
    "INSERT INTO artists (               \n",
    "    artist_id, name, location,\n",
    "    latitude, longitude\n",
    ")\n",
    "SELECT DISTINCT\n",
    "    ss.artist_id                AS artist_id,\n",
    "    ss.artist_name              AS name,\n",
    "    ss.artist_location          AS location,\n",
    "    ss.artist_latitude          AS latitude,\n",
    "    ss.artist_longitude         AS longitude\n",
    "FROM\n",
    "    song_staging AS ss;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Delete the Redshift cluster and IAM role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# redshift.delete_cluster(\n",
    "#     ClusterIdentifier=CLUSTER_NAME,\n",
    "#     SkipFinalClusterSnapshot=True,\n",
    "# )\n",
    "\n",
    "# iam.detach_role_policy(\n",
    "#     RoleName=IAM_ROLE_NAME,\n",
    "#     PolicyArn='arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess',\n",
    "# )\n",
    "# iam.delete_role(RoleName=IAM_ROLE_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
